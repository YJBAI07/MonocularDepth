{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12556530,"sourceType":"datasetVersion","datasetId":7928619}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os, gc, cv2, torch, shutil\nimport numpy as np\nfrom PIL import Image\nfrom transformers import AutoImageProcessor, ZoeDepthForDepthEstimation\n\n# ================== 1) 模型加载（ZoeDepth，米制深度） ==================\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel_name = \"Intel/zoedepth-nyu-kitti\"\nprocessor = AutoImageProcessor.from_pretrained(model_name)\nmodel = ZoeDepthForDepthEstimation.from_pretrained(model_name).to(device).eval()\n\n# ================== 2) 目录 & 工具 ==================\nVAL_ROOT = \"/kaggle/input/diode-val/val\"\nOUT_ROOT = \"/kaggle/working/download\"\nos.makedirs(OUT_ROOT, exist_ok=True)\n\ndef mm_png_save(path, depth_m: np.ndarray):\n    \"\"\"以 16-bit PNG(毫米)保存深度图\"\"\"\n    depth_mm = np.clip(depth_m * 1000.0, 0, 65535).astype(np.uint16)\n    os.makedirs(os.path.dirname(path), exist_ok=True)\n    cv2.imwrite(path, depth_mm)\n\ndef npy_save(path, arr: np.ndarray):\n    os.makedirs(os.path.dirname(path), exist_ok=True\n               )\n    np.save(path, arr.astype(np.float32))\n\ndef scale_match(pred: np.ndarray, gt: np.ndarray, mask: np.ndarray) -> float:\n    \"\"\"每张图的纯缩放对齐（scale-only）\"\"\"\n    v = mask & np.isfinite(gt) & np.isfinite(pred) & (gt > 0)\n    if v.sum() == 0:\n        return 1.0\n    p = pred[v]; g = gt[v]\n    den = float((p**2).sum())\n    return float((g * p).sum() / den) if den > 0 else 1.0\n\n# ================== 3) 递归遍历，保存 预测 + GT ==================\ncount_total, count_saved = 0, 0\n\nfor root, _, files in os.walk(VAL_ROOT):\n    pngs = [f for f in sorted(files) if f.endswith(\".png\")]\n    if not pngs:\n        continue\n\n    # 相对 val 的路径\n    rel_dir = os.path.relpath(root, VAL_ROOT)\n\n    # 导出子目录（按相对路径展开）\n    out_pred_raw_npy   = os.path.join(OUT_ROOT, rel_dir, \"pred_raw_npy\")      # 原始米制预测 .npy\n    out_pred_aligned   = os.path.join(OUT_ROOT, rel_dir, \"pred_aligned_npy\")  # 可选：scale-only 对齐后 .npy\n    out_pred_raw_png16 = os.path.join(OUT_ROOT, rel_dir, \"pred_raw_png16\")    # 原始米制转毫米 16-bit PNG\n    out_gt_npy         = os.path.join(OUT_ROOT, rel_dir, \"gt_npy\")            # GT .npy (米)\n    out_gt_png16       = os.path.join(OUT_ROOT, rel_dir, \"gt_png16\")          # GT 16-bit PNG (毫米)\n\n    for img_name in pngs:\n        count_total += 1\n        rgb_path  = os.path.join(root, img_name)\n        gt_path   = rgb_path.replace(\".png\", \"_depth.npy\")\n        mask_path = rgb_path.replace(\".png\", \"_depth_mask.npy\")\n\n        # DIODE 每张 RGB 对应 *_depth.npy 与 *_depth_mask.npy；缺失则跳过\n        if not (os.path.exists(gt_path) and os.path.exists(mask_path)):\n            continue\n\n        # 读取\n        rgb_bgr = cv2.imread(rgb_path)\n        rgb = cv2.cvtColor(rgb_bgr, cv2.COLOR_BGR2RGB)\n        gt = np.load(gt_path).astype(np.float32)\n        if gt.ndim == 3:\n            gt = gt[..., 0]\n        mask = np.load(mask_path).astype(bool)\n\n        # ------ 推理（得到米制深度，单位=米） ------\n        with torch.no_grad():\n            inputs = processor(images=Image.fromarray(rgb), return_tensors=\"pt\").to(device)\n            outputs = model(**inputs)\n            processed = processor.post_process_depth_estimation(\n                outputs, source_sizes=[(rgb.shape[0], rgb.shape[1])]\n            )\n            pred_metric = processed[0][\"predicted_depth\"].squeeze().detach().cpu().numpy().astype(np.float32)\n\n        # 尺寸对齐到 GT\n        if pred_metric.shape != gt.shape:\n            pred_metric = cv2.resize(pred_metric, (gt.shape[1], gt.shape[0]), interpolation=cv2.INTER_LINEAR)\n\n        # （可选）“scale-only 对齐后”的预测 .npy\n        s = scale_match(pred_metric, gt, mask)\n        pred_aligned = pred_metric * s\n\n        # 文件名（与 RGB 同名）\n        stem = os.path.splitext(img_name)[0]\n\n        # 保存预测（原始米制）\n        npy_save(os.path.join(out_pred_raw_npy,   f\"{stem}.npy\"), pred_metric)\n        mm_png_save(os.path.join(out_pred_raw_png16, f\"{stem}.png\"), pred_metric)\n\n        # 保存预测（对齐后 .npy）\n        npy_save(os.path.join(out_pred_aligned,   f\"{stem}.npy\"), pred_aligned)\n\n        # 保存 GT（米制）\n        npy_save(os.path.join(out_gt_npy,     f\"{stem}.npy\"), gt)\n        mm_png_save(os.path.join(out_gt_png16, f\"{stem}.png\"), gt)\n\n        count_saved += 1\n\n        # 清理\n        del rgb_bgr, rgb, gt, mask, pred_metric, pred_aligned, inputs, outputs, processed\n        gc.collect()\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n\nprint(f\"[ZoeDepth SAVE] scanned PNGs: {count_total}, saved pairs: {count_saved}\")\n\n# ================== 4) （可选）一键打包下载 ==================\nzip_base = \"/kaggle/working/zoedepth_diode_preds_and_gt\"\nshutil.make_archive(zip_base, \"zip\", OUT_ROOT)\nprint(f\"打包完成: {zip_base}.zip\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-14T16:46:33.009205Z","iopub.execute_input":"2025-08-14T16:46:33.009493Z","iopub.status.idle":"2025-08-14T17:04:40.118164Z","shell.execute_reply.started":"2025-08-14T16:46:33.009474Z","shell.execute_reply":"2025-08-14T17:04:40.117522Z"}},"outputs":[{"name":"stderr","text":"2025-08-14 16:46:43.982441: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1755190004.174947      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1755190004.236196      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/723 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5869fa16e3c942bc9c87fc366784fe06"}},"metadata":{}},{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46d8f5bbbe0e448ab805b821f91955a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.38G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"899cdeff02c845af9c28c671b4ecbd11"}},"metadata":{}},{"name":"stdout","text":"[ZoeDepth SAVE] scanned PNGs: 771, saved pairs: 771\n打包完成: /kaggle/working/zoedepth_diode_preds_and_gt.zip\n","output_type":"stream"}],"execution_count":1}]}