{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12568056,"sourceType":"datasetVersion","datasetId":7936848}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os, gc, cv2, torch, shutil\nimport numpy as np\nfrom PIL import Image\nfrom transformers import AutoImageProcessor, ZoeDepthForDepthEstimation\n\n# ===== 1) 模型加载 =====\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel_name = \"Intel/zoedepth-nyu-kitti\"\nprocessor = AutoImageProcessor.from_pretrained(model_name)\nmodel = ZoeDepthForDepthEstimation.from_pretrained(model_name).to(device).eval()\n\n# ===== 2) 路径 =====\nbase_dir = \"/kaggle/input/kitti-dataset/depth_selection/val_selection_cropped\"\nimg_dir = os.path.join(base_dir, \"image\")\ngt_dir  = os.path.join(base_dir, \"groundtruth_depth\")\n\nOUT_ROOT = \"/kaggle/working/download/kitti\"\nfor d in [\"pred_raw_npy\",\"pred_aligned_npy\",\"pred_raw_png16\",\"gt_npy\",\"gt_png16\"]:\n    os.makedirs(os.path.join(OUT_ROOT, d), exist_ok=True)\n\n# ===== 3) 工具 =====\ndef npy_save(path, arr): np.save(path, arr.astype(np.float32))\ndef mm_png_save(path, depth_m):\n    depth_mm = np.clip(depth_m * 1000.0, 0, 65535).astype(np.uint16)\n    cv2.imwrite(path, depth_mm)\n\ndef scale_match(pred, gt, mask):\n    v = mask & np.isfinite(gt) & np.isfinite(pred) & (gt > 0)\n    if not np.any(v): return 1.0\n    p, g = pred[v], gt[v]\n    den = float((p**2).sum())\n    return float((g * p).sum() / den) if den > 0 else 1.0\n\n# ===== 4) 主循环：保存 预测 + GT =====\nimg_files = sorted(f for f in os.listdir(img_dir) if f.endswith(\".png\"))\nsaved = 0\n\nfor img_file in img_files:\n    # GT 文件名：将首个 \"_image_\" 换为 \"_groundtruth_depth_\"\n    gt_file = img_file.replace(\"_image_\", \"_groundtruth_depth_\", 1)\n    rgb_path = os.path.join(img_dir, img_file)\n    gt_path  = os.path.join(gt_dir,  gt_file)\n    if not os.path.exists(gt_path):\n        continue\n\n    # 读取 RGB / GT（KITTI 16-bit PNG → 米）\n    rgb_bgr = cv2.imread(rgb_path)\n    if rgb_bgr is None:\n        continue\n    rgb = cv2.cvtColor(rgb_bgr, cv2.COLOR_BGR2RGB)\n\n    gt_png = cv2.imread(gt_path, cv2.IMREAD_UNCHANGED)\n    if gt_png is None:\n        continue\n    gt_depth = gt_png.astype(np.float32) / 256.0\n    mask = gt_depth > 0\n\n    # 推理（ZoeDepth 输出米制）\n    with torch.no_grad():\n        inputs = processor(images=Image.fromarray(rgb), return_tensors=\"pt\").to(device)\n        outputs = model(**inputs)\n        processed = processor.post_process_depth_estimation(\n            outputs, source_sizes=[(rgb.shape[0], rgb.shape[1])]\n        )\n        pred_metric = processed[0][\"predicted_depth\"].squeeze().detach().cpu().numpy().astype(np.float32)\n\n    # 尺寸对齐\n    if pred_metric.shape != gt_depth.shape:\n        pred_metric = cv2.resize(pred_metric, (gt_depth.shape[1], gt_depth.shape[0]), interpolation=cv2.INTER_LINEAR)\n\n    # （可选）scale-only 对齐一份\n    s = scale_match(pred_metric, gt_depth, mask)\n    pred_aligned = pred_metric * s\n\n    stem = os.path.splitext(img_file)[0]\n\n    # 保存预测（原始 + 16-bit 毫米 PNG）\n    npy_save(os.path.join(OUT_ROOT, \"pred_raw_npy\",     f\"{stem}.npy\"), pred_metric)\n    mm_png_save(os.path.join(OUT_ROOT, \"pred_raw_png16\", f\"{stem}.png\"), pred_metric)\n\n    # 保存预测（对齐后 .npy）\n    npy_save(os.path.join(OUT_ROOT, \"pred_aligned_npy\", f\"{stem}.npy\"), pred_aligned)\n\n    # 保存 GT（米 + 16-bit 毫米 PNG）\n    npy_save(os.path.join(OUT_ROOT, \"gt_npy\",     f\"{stem}.npy\"), gt_depth)\n    mm_png_save(os.path.join(OUT_ROOT, \"gt_png16\", f\"{stem}.png\"), gt_depth)\n\n    saved += 1\n\n    # 清理\n    del rgb_bgr, rgb, gt_depth, pred_metric, pred_aligned, inputs, outputs, processed\n    gc.collect()\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n\nprint(f\"[KITTI ZoeDepth SAVE] saved pairs: {saved} / {len(img_files)}\")\n\n# ===== 5) 打包下载 =====\nzip_base = \"/kaggle/working/zoe_kitti_preds_and_gt\"\nshutil.make_archive(zip_base, \"zip\", OUT_ROOT)\nprint(f\"打包完成: {zip_base}.zip\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-14T18:13:47.777365Z","iopub.execute_input":"2025-08-14T18:13:47.777614Z","iopub.status.idle":"2025-08-14T18:37:39.148726Z","shell.execute_reply.started":"2025-08-14T18:13:47.777590Z","shell.execute_reply":"2025-08-14T18:37:39.148026Z"}},"outputs":[{"name":"stderr","text":"2025-08-14 18:13:59.577656: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1755195239.782224      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1755195239.853172      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/723 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52d0346db3f1499a80534fdd025ffcce"}},"metadata":{}},{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffbc54f998314b4c95ad26e4177b8f9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.38G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"729d93f039804f1daa086b4d5a346305"}},"metadata":{}},{"name":"stdout","text":"[KITTI ZoeDepth SAVE] saved pairs: 1000 / 1000\n打包完成: /kaggle/working/zoe_kitti_preds_and_gt.zip\n","output_type":"stream"}],"execution_count":1}]}